{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLPnasGq4-sn"
      },
      "source": [
        "## Auhtor\n",
        "Muhamad Nur Syami\n",
        "\n",
        "Copyright 2025\n",
        "\n",
        "ulasan penulis Muhamad Nur Syami :\n",
        "Kode ini dipergunakan untuk menyelesaikan jenjang studi S1 Sarjana Teknik/Computer Science Program Studi Teknik Informatika Universitas Maritim Raja Ali Haji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6XRA519WveX",
        "outputId": "f1eff408-7c19-4e7b-a4ba-f49d4eee0192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.63-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.57.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.63-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.63\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# ✅ INSTALL DEPENDENCIES & MOUNT DRIVE\n",
        "# =======================================\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install pycocotools roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY0y4nkBc1Rx",
        "outputId": "f7bb6554-8a7a-4a4f-ab70-ee55d86acd22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os, shutil\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SCPX3xyc68G",
        "outputId": "6a2eea77-c712-457f-b11d-e07963014e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.1.63)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Requirement already satisfied: pillow-heif>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.22.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Mangrove-Bintan-1 to coco:: 100%|██████████| 260315/260315 [00:15<00:00, 16689.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Mangrove-Bintan-1 in coco:: 100%|██████████| 5408/5408 [00:01<00:00, 4618.75it/s]\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# ✅ DOWNLOAD DATASET FROM ROBOFLOW\n",
        "# =======================================\n",
        "# Ini hanya demo saja, dan dataset ini sudah diganti dan tidak bisa digunakand dikarenakan hak cipta dataset,\n",
        "# jadi silahkan pakai dataset anda yang telah anda labeling di aplikasi robotflow\n",
        "# dan gunakan format coco json dengan api key dari robotflow.\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"asldjwuaksdj913\")\n",
        "project = rf.workspace(\"jhon\").project(\"anonymous-dummy\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"coco\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekOgTKhNc8-u"
      },
      "outputs": [],
      "source": [
        "# =======================================\n",
        "# ✅ IMPORT LIBRARY UTAMA\n",
        "# =======================================\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.transforms import functional as F\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e852HS9eoWN0",
        "outputId": "7b21e8c6-397d-463e-a505-ffdf11875cfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📁 Validasi File: /content/Mangrove-Bintan-1/train/_annotations.coco.json\n",
            "✅ Struktur Valid\n",
            "Total Images: 3780\n",
            "Total Annotations: 4014\n",
            "Total Categories: 10\n",
            "Categories: ['Avicennia-lanata', 'Avicennia-lanata', 'Bruguiera-cylindrica', 'Bruguiera-gymnorrhiza', 'Lumnitzera-liitorea', 'Rhizophora-apiculata', 'Rhizophora-mucronata', 'Scyphiphora-hydrophyllacea', 'Sonneratia-alba', 'Xylocarpus-granatum']\n",
            "\n",
            "📊 Distribusi Anotasi per Kategori:\n",
            "  Avicennia-lanata: 0 anotasi\n",
            "  Avicennia-lanata: 456 anotasi\n",
            "  Bruguiera-cylindrica: 462 anotasi\n",
            "  Bruguiera-gymnorrhiza: 435 anotasi\n",
            "  Lumnitzera-liitorea: 442 anotasi\n",
            "  Rhizophora-apiculata: 413 anotasi\n",
            "  Rhizophora-mucronata: 464 anotasi\n",
            "  Scyphiphora-hydrophyllacea: 438 anotasi\n",
            "  Sonneratia-alba: 414 anotasi\n",
            "  Xylocarpus-granatum: 490 anotasi\n",
            "\n",
            "📁 Validasi File: /content/Mangrove-Bintan-1/valid/_annotations.coco.json\n",
            "✅ Struktur Valid\n",
            "Total Images: 1080\n",
            "Total Annotations: 1163\n",
            "Total Categories: 10\n",
            "Categories: ['Avicennia-lanata', 'Avicennia-lanata', 'Bruguiera-cylindrica', 'Bruguiera-gymnorrhiza', 'Lumnitzera-liitorea', 'Rhizophora-apiculata', 'Rhizophora-mucronata', 'Scyphiphora-hydrophyllacea', 'Sonneratia-alba', 'Xylocarpus-granatum']\n",
            "\n",
            "📊 Distribusi Anotasi per Kategori:\n",
            "  Avicennia-lanata: 0 anotasi\n",
            "  Avicennia-lanata: 134 anotasi\n",
            "  Bruguiera-cylindrica: 131 anotasi\n",
            "  Bruguiera-gymnorrhiza: 118 anotasi\n",
            "  Lumnitzera-liitorea: 125 anotasi\n",
            "  Rhizophora-apiculata: 134 anotasi\n",
            "  Rhizophora-mucronata: 133 anotasi\n",
            "  Scyphiphora-hydrophyllacea: 116 anotasi\n",
            "  Sonneratia-alba: 150 anotasi\n",
            "  Xylocarpus-granatum: 122 anotasi\n",
            "\n",
            "📁 Validasi File: /content/Mangrove-Bintan-1/test/_annotations.coco.json\n",
            "✅ Struktur Valid\n",
            "Total Images: 540\n",
            "Total Annotations: 571\n",
            "Total Categories: 10\n",
            "Categories: ['Avicennia-lanata', 'Avicennia-lanata', 'Bruguiera-cylindrica', 'Bruguiera-gymnorrhiza', 'Lumnitzera-liitorea', 'Rhizophora-apiculata', 'Rhizophora-mucronata', 'Scyphiphora-hydrophyllacea', 'Sonneratia-alba', 'Xylocarpus-granatum']\n",
            "\n",
            "📊 Distribusi Anotasi per Kategori:\n",
            "  Avicennia-lanata: 0 anotasi\n",
            "  Avicennia-lanata: 56 anotasi\n",
            "  Bruguiera-cylindrica: 65 anotasi\n",
            "  Bruguiera-gymnorrhiza: 73 anotasi\n",
            "  Lumnitzera-liitorea: 63 anotasi\n",
            "  Rhizophora-apiculata: 56 anotasi\n",
            "  Rhizophora-mucronata: 65 anotasi\n",
            "  Scyphiphora-hydrophyllacea: 59 anotasi\n",
            "  Sonneratia-alba: 62 anotasi\n",
            "  Xylocarpus-granatum: 72 anotasi\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# ✅ FUNGSI VALIDASI STRUKTUR DAN STATISTIK DATASET (DITAMBAH DISTRIBUSI KATEGORI)\n",
        "# =======================================\n",
        "def validate_and_summarize_coco(json_path):\n",
        "    with open(json_path) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(f\"\\n📁 Validasi File: {json_path}\")\n",
        "    for key in ['images', 'annotations', 'categories']:\n",
        "        if key not in data:\n",
        "            print(f\"❌ Missing key: {key}\")\n",
        "            return\n",
        "\n",
        "    print(\"✅ Struktur Valid\")\n",
        "    print(f\"Total Images: {len(data['images'])}\")\n",
        "    print(f\"Total Annotations: {len(data['annotations'])}\")\n",
        "    print(f\"Total Categories: {len(data['categories'])}\")\n",
        "\n",
        "    # Tampilkan daftar kategori\n",
        "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    print(f\"Categories: {list(categories.values())}\")\n",
        "\n",
        "    # Hitung distribusi anotasi per kategori\n",
        "    annotation_counts = {cat_id: 0 for cat_id in categories.keys()}\n",
        "    for ann in data['annotations']:\n",
        "        cat_id = ann['category_id']\n",
        "        if cat_id in annotation_counts:\n",
        "            annotation_counts[cat_id] += 1\n",
        "\n",
        "    print(\"\\n📊 Distribusi Anotasi per Kategori:\")\n",
        "    for cat_id, count in annotation_counts.items():\n",
        "        print(f\"  {categories[cat_id]}: {count} anotasi\")\n",
        "\n",
        "# Silahkan sesuaikan path dataset anda\n",
        "validate_and_summarize_coco(\"/content/Dummy-Dummy-1/train/_annotations.coco.json\")\n",
        "validate_and_summarize_coco(\"/content/Dummy-Dummy-1/valid/_annotations.coco.json\")\n",
        "validate_and_summarize_coco(\"/content/Dummy-Dummy-1/test/_annotations.coco.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCsHob8GoZB8",
        "outputId": "7eacce18-9dc0-427f-da7f-0c846cac9e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# ✅ TRANSFORMASI & DATASET\n",
        "# =======================================\n",
        "class CocoTransform:\n",
        "    def __call__(self, image, target):\n",
        "        image = F.to_tensor(image)\n",
        "        return image, target\n",
        "\n",
        "def get_coco_dataset(img_dir, ann_file):\n",
        "    return CocoDetection(root=img_dir, annFile=ann_file, transforms=CocoTransform())\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "train_dataset = get_coco_dataset(\"/content/Dummy-Dummy-1/train\", \"/content/Dummy-Dummy-1/train/_annotations.coco.json\")\n",
        "val_dataset = get_coco_dataset(\"/content/Dummy-Dummy-1/valid\", \"/content/Dummy-Dummy-1/valid/_annotations.coco.json\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75HKJIcSocla",
        "outputId": "dcc6a53b-1fd2-4dda-c28d-a04fde966901"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:01<00:00, 87.7MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =======================================\n",
        "# ✅ INISIALISASI MODEL\n",
        "# =======================================\n",
        "\n",
        "\n",
        "def get_model(num_classes):\n",
        "\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1')\n",
        "\n",
        "    # Ganti detection head (box predictor)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "num_classes = 10\n",
        "model = get_model(num_classes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzZ2asoiaphJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otdrAB8R3MeT"
      },
      "outputs": [],
      "source": [
        "# =======================================\n",
        "# ✅ TRAINING DAN EVALUASI PER EPOCH\n",
        "# =======================================\n",
        "all_losses = []\n",
        "map_per_epoch = []\n",
        "ap_per_class_epoch = []\n",
        "\n",
        "# Background default, dan tidak perlu di hapus dan di ganti, silakan lanjut dan dimulai dari nomor 1 untuk menganti kelas yang anda inginkan.\n",
        "COCO_CLASSES = {\n",
        "    0: \"Background\",\n",
        "    1: \"Dummy-Dummy\",\n",
        "    2: \"Dummy-Dummy\",\n",
        "    3: \"Dummy-Dummy\",\n",
        "    4: \"Dummy-Dummy\",\n",
        "    5: \"Dummy-Dummy\",\n",
        "    6: \"Dummy-Dummy\",\n",
        "    7: \"Dummy-Dummy\",\n",
        "    8: \"Dummy-Dummy\",\n",
        "    9: \"Dummy-Dummy\",\n",
        "}\n",
        "\n",
        "num_epochs = 25\n",
        "# Mmebuat Folder untuk menyimpan hasil training seperti model dan visualiasi berdasarkan best model.:\n",
        "save_dir = \"/content/drive/MyDrive/training_model/tanpa_augmentasi_25epoch_4bacthsize\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, targets in data_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        processed_targets = []\n",
        "        valid_images = []\n",
        "        for i, target in enumerate(targets):\n",
        "            boxes, labels = [], []\n",
        "            for obj in target:\n",
        "                x, y, w, h = obj[\"bbox\"]\n",
        "                if w > 0 and h > 0:\n",
        "                    boxes.append([x, y, x+w, y+h])\n",
        "                    labels.append(obj[\"category_id\"])\n",
        "            if boxes:\n",
        "                processed_targets.append({\n",
        "                    \"boxes\": torch.tensor(boxes, dtype=torch.float32).to(device),\n",
        "                    \"labels\": torch.tensor(labels, dtype=torch.int64).to(device)\n",
        "                })\n",
        "                valid_images.append(images[i])\n",
        "        if not processed_targets:\n",
        "            continue\n",
        "        loss_dict = model(valid_images, processed_targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        total_loss += losses.item()\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    all_losses.append(avg_loss)\n",
        "    print(f\"Epoch [{epoch+1}] Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def evaluate_model(model, data_loader, ann_file):\n",
        "    model.eval()\n",
        "    coco_gt = COCO(ann_file)\n",
        "    results = []\n",
        "    for images, targets in data_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        for i, output in enumerate(outputs):\n",
        "            image_id = targets[i][0][\"image_id\"]\n",
        "            for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
        "                x_min, y_min, x_max, y_max = box.cpu().numpy()\n",
        "                width = x_max - x_min\n",
        "                height = y_max - y_min\n",
        "                results.append({\n",
        "                    \"image_id\": int(image_id),\n",
        "                    \"category_id\": int(label),\n",
        "                    \"bbox\": [x_min, y_min, width, height],\n",
        "                    \"score\": float(score)\n",
        "                })\n",
        "    coco_dt = coco_gt.loadRes(results)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "\n",
        "    #Kode MAP\n",
        "    global_map = coco_eval.stats[0] * 100 # mAP pada IoU=0.5:0.95\n",
        "    map_per_epoch.append(global_map)\n",
        "    # Kode AP\n",
        "    ap_per_class = {}\n",
        "    for i, cat_id in enumerate(coco_eval.params.catIds):\n",
        "        ap = np.mean(coco_eval.eval['precision'][0, :, i, 0, -1]) * 100\n",
        "        class_name = COCO_CLASSES.get(cat_id, f\"Class {cat_id}\")\n",
        "        ap_per_class[class_name] = ap\n",
        "        print(f\"  AP @{class_name}: {ap:.2f}%\")\n",
        "\n",
        "    ap_per_class_epoch.append(ap_per_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ou2ueTk3OSD",
        "outputId": "2038afda-8a47-4c41-89cf-aef7ded5e95c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Epoch 1/25 ====\n",
            "Epoch [1] Training Loss: 0.1883\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.28s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.388\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.576\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.652\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 90.00%\n",
            "  AP @Bruguiera-cylindrica: 54.88%\n",
            "  AP @Bruguiera-gymnorrhiza: 72.39%\n",
            "  AP @Lumnitzera-liitorea: 94.22%\n",
            "  AP @Rhizophora-apiculata: 70.75%\n",
            "  AP @Rhizophora-mucronata: 59.45%\n",
            "  AP @Scyphiphora-hydrophyllacea: 88.09%\n",
            "  AP @Sonneratia-alba: 93.57%\n",
            "  AP @Xylocarpus-granatum: 60.99%\n",
            "Epoch 1: mAP = 41.01%\n",
            "🏆 Best model saved at epoch 1 with mAP: 41.01%\n",
            "\n",
            "==== Epoch 2/25 ====\n",
            "Epoch [2] Training Loss: 0.1081\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.96s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.837\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.527\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.617\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.685\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 90.93%\n",
            "  AP @Bruguiera-cylindrica: 52.01%\n",
            "  AP @Bruguiera-gymnorrhiza: 82.36%\n",
            "  AP @Lumnitzera-liitorea: 95.70%\n",
            "  AP @Rhizophora-apiculata: 91.92%\n",
            "  AP @Rhizophora-mucronata: 72.66%\n",
            "  AP @Scyphiphora-hydrophyllacea: 89.05%\n",
            "  AP @Sonneratia-alba: 97.14%\n",
            "  AP @Xylocarpus-granatum: 81.80%\n",
            "Epoch 2: mAP = 49.91%\n",
            "🏆 Best model saved at epoch 2 with mAP: 49.91%\n",
            "\n",
            "==== Epoch 3/25 ====\n",
            "Epoch [3] Training Loss: 0.0884\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.61s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.857\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.585\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.634\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 88.64%\n",
            "  AP @Bruguiera-cylindrica: 66.46%\n",
            "  AP @Bruguiera-gymnorrhiza: 89.50%\n",
            "  AP @Lumnitzera-liitorea: 96.67%\n",
            "  AP @Rhizophora-apiculata: 94.69%\n",
            "  AP @Rhizophora-mucronata: 78.86%\n",
            "  AP @Scyphiphora-hydrophyllacea: 95.75%\n",
            "  AP @Sonneratia-alba: 94.50%\n",
            "  AP @Xylocarpus-granatum: 65.86%\n",
            "Epoch 3: mAP = 52.81%\n",
            "🏆 Best model saved at epoch 3 with mAP: 52.81%\n",
            "\n",
            "==== Epoch 4/25 ====\n",
            "Epoch [4] Training Loss: 0.0613\n",
            "loading annotations into memory...\n",
            "Done (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.47s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.12s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.696\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.672\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.726\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.726\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 97.69%\n",
            "  AP @Bruguiera-cylindrica: 74.93%\n",
            "  AP @Bruguiera-gymnorrhiza: 91.85%\n",
            "  AP @Lumnitzera-liitorea: 97.55%\n",
            "  AP @Rhizophora-apiculata: 96.24%\n",
            "  AP @Rhizophora-mucronata: 89.36%\n",
            "  AP @Scyphiphora-hydrophyllacea: 98.39%\n",
            "  AP @Sonneratia-alba: 98.48%\n",
            "  AP @Xylocarpus-granatum: 90.89%\n",
            "Epoch 4: mAP = 62.15%\n",
            "🏆 Best model saved at epoch 4 with mAP: 62.15%\n",
            "\n",
            "==== Epoch 5/25 ====\n",
            "Epoch [5] Training Loss: 0.0561\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.60s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.937\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.717\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 97.64%\n",
            "  AP @Bruguiera-cylindrica: 78.54%\n",
            "  AP @Bruguiera-gymnorrhiza: 92.75%\n",
            "  AP @Lumnitzera-liitorea: 97.39%\n",
            "  AP @Rhizophora-apiculata: 96.22%\n",
            "  AP @Rhizophora-mucronata: 91.36%\n",
            "  AP @Scyphiphora-hydrophyllacea: 99.49%\n",
            "  AP @Sonneratia-alba: 97.56%\n",
            "  AP @Xylocarpus-granatum: 92.12%\n",
            "Epoch 5: mAP = 63.25%\n",
            "🏆 Best model saved at epoch 5 with mAP: 63.25%\n",
            "\n",
            "==== Epoch 6/25 ====\n",
            "Epoch [6] Training Loss: 0.0534\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.61s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.12s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.929\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.714\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.672\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 96.27%\n",
            "  AP @Bruguiera-cylindrica: 74.26%\n",
            "  AP @Bruguiera-gymnorrhiza: 93.71%\n",
            "  AP @Lumnitzera-liitorea: 97.47%\n",
            "  AP @Rhizophora-apiculata: 95.74%\n",
            "  AP @Rhizophora-mucronata: 90.42%\n",
            "  AP @Scyphiphora-hydrophyllacea: 99.26%\n",
            "  AP @Sonneratia-alba: 97.74%\n",
            "  AP @Xylocarpus-granatum: 91.43%\n",
            "Epoch 6: mAP = 62.44%\n",
            "\n",
            "==== Epoch 7/25 ====\n",
            "Epoch [7] Training Loss: 0.0498\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.932\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.714\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.679\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.731\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 97.56%\n",
            "  AP @Bruguiera-cylindrica: 74.85%\n",
            "  AP @Bruguiera-gymnorrhiza: 91.85%\n",
            "  AP @Lumnitzera-liitorea: 97.51%\n",
            "  AP @Rhizophora-apiculata: 96.83%\n",
            "  AP @Rhizophora-mucronata: 90.69%\n",
            "  AP @Scyphiphora-hydrophyllacea: 99.43%\n",
            "  AP @Sonneratia-alba: 97.72%\n",
            "  AP @Xylocarpus-granatum: 92.32%\n",
            "Epoch 7: mAP = 63.61%\n",
            "🏆 Best model saved at epoch 7 with mAP: 63.61%\n",
            "\n",
            "==== Epoch 8/25 ====\n",
            "Epoch [8] Training Loss: 0.0491\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.65s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.933\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.712\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.637\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.678\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 97.57%\n",
            "  AP @Bruguiera-cylindrica: 75.37%\n",
            "  AP @Bruguiera-gymnorrhiza: 91.74%\n",
            "  AP @Lumnitzera-liitorea: 97.49%\n",
            "  AP @Rhizophora-apiculata: 96.65%\n",
            "  AP @Rhizophora-mucronata: 90.95%\n",
            "  AP @Scyphiphora-hydrophyllacea: 99.33%\n",
            "  AP @Sonneratia-alba: 97.73%\n",
            "  AP @Xylocarpus-granatum: 92.43%\n",
            "Epoch 8: mAP = 63.57%\n",
            "\n",
            "==== Epoch 9/25 ====\n",
            "Epoch [9] Training Loss: 0.0487\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.81s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.634\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.933\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.727\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.727\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 97.61%\n",
            "  AP @Bruguiera-cylindrica: 75.22%\n",
            "  AP @Bruguiera-gymnorrhiza: 91.66%\n",
            "  AP @Lumnitzera-liitorea: 97.50%\n",
            "  AP @Rhizophora-apiculata: 96.57%\n",
            "  AP @Rhizophora-mucronata: 91.07%\n",
            "  AP @Scyphiphora-hydrophyllacea: 99.31%\n",
            "  AP @Sonneratia-alba: 97.75%\n",
            "  AP @Xylocarpus-granatum: 92.63%\n",
            "Epoch 9: mAP = 63.45%\n",
            "\n",
            "==== Epoch 10/25 ====\n",
            "Epoch [10] Training Loss: 0.0482\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.933\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.637\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.678\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.728\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.728\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730\n",
            "  AP @Background: -100.00%\n",
            "  AP @Avicennia-lanata: 97.56%\n",
            "  AP @Bruguiera-cylindrica: 75.31%\n",
            "  AP @Bruguiera-gymnorrhiza: 91.69%\n",
            "  AP @Lumnitzera-liitorea: 97.50%\n",
            "  AP @Rhizophora-apiculata: 96.57%\n",
            "  AP @Rhizophora-mucronata: 91.04%\n",
            "  AP @Scyphiphora-hydrophyllacea: 99.35%\n",
            "  AP @Sonneratia-alba: 97.74%\n",
            "  AP @Xylocarpus-granatum: 92.56%\n",
            "Epoch 10: mAP = 63.57%\n",
            "\n",
            "==== Epoch 11/25 ====\n"
          ]
        }
      ],
      "source": [
        "best_map = 0.0\n",
        "best_model_path = os.path.join(save_dir, \"best_model.pth\")\n",
        "save_per_epoch = False  # Set ke False jika tidak ingin simpan tiap epoch\n",
        "\n",
        "# Loop training\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n==== Epoch {epoch+1}/{num_epochs} ====\")\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    evaluate_model(model, val_loader, \"/content/Mangrove-Bintan-1/valid/_annotations.coco.json\")\n",
        "\n",
        "    current_map = map_per_epoch[-1]\n",
        "    print(f\"Epoch {epoch+1}: mAP = {current_map:.2f}%\")\n",
        "\n",
        "    # Simpan model terbaik berdasarkan mAP\n",
        "    if current_map > best_map:\n",
        "        best_map = current_map\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"🏆 Best model saved at epoch {epoch+1} with mAP: {best_map:.2f}%\")\n",
        "\n",
        "    # Simpan model setiap epoch jika diperlukan\n",
        "    if save_per_epoch:\n",
        "        save_path = os.path.join(save_dir, f\"fasterrcnn_resnet50_epoch_{epoch+1}.pth\")\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"✅ Model saved: {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6H_AOq73R3d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =======================================\n",
        "# ✅ VISUALISASI LOSS, mAP, AP PER KELAS\n",
        "# =======================================\n",
        "save_dir = \"/content/drive/MyDrive/training_model/tanpa_augmentasi_25epoch_4bacthsize\"\n",
        "# Visualisasi Training Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, num_epochs + 1), all_losses, marker='o', color='b')\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "training_loss_path = \"/content/drive/MyDrive/training_model/tanpa_augmentasi_25epoch_4bacthsize/training_loss_plot.png\"\n",
        "plt.savefig(training_loss_path)\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(f\"Training Loss plot saved at: {training_loss_path}\")\n",
        "\n",
        "# Visualisasi Validation mAP [IoU=0.50:0.95]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, num_epochs + 1), map_per_epoch, marker='o', color='green')\n",
        "plt.title(\"Validation mAP [IoU=0.50:0.95]\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"mAP (%)\")\n",
        "plt.grid(True)\n",
        "validation_map_path = \"/content/drive/MyDrive/training_model/tanpa_augmentasi_25epoch_4bacthsize/validation_map_plot.png\"\n",
        "plt.savefig(validation_map_path)\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(f\"Validation mAP plot saved at: {validation_map_path}\")\n",
        "\n",
        "# Visualisasi AP per Class\n",
        "plt.figure(figsize=(12, 8))\n",
        "for class_name in ap_per_class_epoch[0].keys():\n",
        "    ap_values = [epoch_ap.get(class_name, 0) for epoch_ap in ap_per_class_epoch]\n",
        "    plt.plot(range(1, num_epochs + 1), ap_values, label=class_name)\n",
        "\n",
        "plt.title(\"Validation AP per Class\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"AP (%)\")\n",
        "\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "plt.grid(True)\n",
        "\n",
        "# Menyimpan dan menampilkan plot\n",
        "ap_per_class_path = \"/content/drive/MyDrive/training_model/tanpa_augmentasi_25epoch_4bacthsize/ap_per_class_plot.png\"\n",
        "plt.tight_layout()  # Menghindari pemotongan\n",
        "plt.savefig(ap_per_class_path, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(f\"AP per Class plot saved at: {ap_per_class_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxXYm9mH3XMM"
      },
      "outputs": [],
      "source": [
        "# Predict gambar  menggunakan gambar testing atau yang anda upload untuk menguji model\n",
        "\n",
        "img_path = \"/content/hhsmfuk4nfd.jpg\"\n",
        "image_tensor, image_raw = prepare_image(img_path)\n",
        "with torch.no_grad():\n",
        "    prediction = model(image_tensor)\n",
        "draw_boxes(image_raw, prediction)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
